import torch
import torch.nn as nn
from torch.optim import AdamW
from tqdm import tqdm
import numpy as np
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt
import seaborn as sns
import os
import pandas as pd
from datetime import datetime
from GetDataLoader import GetDataLoader
from model import SentimentClassifier, LSTMSentimentClassifier, GRUSentimentClassifier, BiGRUSentimentClassifier
import json
# ===== è‡ªå‹•çµ„åˆå¯¦é©—è¨­å®š =====
AUTO_EXPERIMENT = True  # è¨­ç‚º True å•Ÿå‹•è‡ªå‹•çµ„åˆå¯¦é©—ï¼ŒFalse å‰‡ä½¿ç”¨ä¸‹æ–¹å–®ä¸€é…ç½®

# çµ„åˆå¯¦é©—çš„åƒæ•¸ç¯„åœï¼ˆåŸºæ–¼æœ€ä½³é…ç½®ï¼‰
EXPERIMENT_CONFIGS = {
    'MODEL_NAMES': [
        # --- åŸå§‹åƒè€ƒ / ä¸ä½¿ç”¨ ---
        # 'intfloat/multilingual-e5-large',       # 560M åƒæ•¸, å¤šèªè¨€æ¨¡å‹
        # 'bert-base-chinese',                    # 102M åƒæ•¸, BERT ä¸­æ–‡ç‰ˆ
        # 'hfl/chinese-bert-wwm-ext',             # 102M åƒæ•¸, BERT ä¸­æ–‡å…¨è©é®ç½©
        # --- ç¾æœ‰æ¸…å–® ---
        # 'uer/roberta-base-finetuned-dianping-chinese',  # 125M åƒæ•¸, RoBERTa ä¸­æ–‡é»è©•å¾®èª¿ç‰ˆ (é–‹ç®±å³ç”¨)
        # 'hfl/chinese-roberta-wwm-ext',                  # 102M åƒæ•¸, RoBERTa ä¸­æ–‡å…¨è©é®ç½© (ç©©å¥ Baseline)
        'IDEA-CCNL/Erlangshen-RoBERTa-110M-Sentiment',  # 110M åƒæ•¸, Erlangshen RoBERTa æƒ…æ„Ÿåˆ†æç‰ˆ
        # --- æ–°å¢æ¨è–¦æ¨¡å‹ ---
        # 'hfl/chinese-macbert-base',                     # 102M åƒæ•¸, MacBERT (ä¸­æ–‡ç³¾éŒ¯å¼é è¨“ç·´ï¼Œé€šå¸¸æ¯” RoBERTa æº–)
        # 'hfl/rbt3',                                     # 38M åƒæ•¸, RBT3 (åƒ… 3 å±¤ Transformerï¼Œæ¨è«–æ¥µå¿«ï¼Œé©åˆå¤§é‡æ•¸æ“š)
        # 'hfl/chinese-electra-180g-base-discriminator',  # 102M åƒæ•¸, ELECTRA (åˆ¤åˆ¥å¼æ¶æ§‹ï¼Œå°æ¨¡ç³Šèªæ„åˆ†è¾¨èƒ½åŠ›ä½³)
    ],
    'HIDDEN_SIZES': [512],   # æœ€ä½³é…ç½®: 256ï¼ˆæ€§èƒ½èˆ‡æ•ˆç‡å¹³è¡¡ï¼‰
    'DROPOUT_RATES': [0.3],  # æœ€ä½³ç¯„åœ: 0.2-0.3
    'SCHEDULERS': ['none'],  # æœ€ä½³é…ç½®: å›ºå®šå­¸ç¿’ç‡
    'MODEL_TYPES': ['simple'],  # 'simple', 'lstm', 'gru', 'bigru'
}
# ===== å–®ä¸€å¯¦é©—è¶…åƒæ•¸è¨­å®šï¼ˆç•¶ AUTO_EXPERIMENT = False æ™‚ä½¿ç”¨ï¼‰=====
# MODEL_NAME = "intfloat/multilingual-e5-large"  # é è¨“ç·´æ¨¡å‹
with open('Key.json', 'r', encoding='utf-8') as f:
    data = json.load(f)
USE_AUTH_TOKEN = data.get('Key')
TRAIN_PATH = r'archive\mental_heath_unbanlanced.csv'  # è¨“ç·´è³‡æ–™è·¯å¾‘
TEST_PATH = r'archive\mental_heath_unbanlanced.csv'    # æ¸¬è©¦è³‡æ–™è·¯å¾‘
VAL_PATH = None  # é©—è­‰è³‡æ–™è·¯å¾‘ (None è¡¨ç¤ºå¾è¨“ç·´è³‡æ–™ä¸­åˆ†å‰²)

BATCH_SIZE = 200
LEARNING_RATE = 2e-5
NUM_EPOCHS = 50
# HIDDEN_SIZE = 256
NUM_CLASSES = 4  # æ­£é¢/è² é¢

# å¯¦é©—çµæœä¸»è³‡æ–™å¤¾
EXPERIMENTS_DIR = 'Experimental_results'
os.makedirs(EXPERIMENTS_DIR, exist_ok=True)

# ===== è¨­å®šè£ç½® =====
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# ===== è¨“ç·´å‡½æ•¸ =====
def train_epoch(model, dataloader, optimizer, device):
    """å–®å€‹ epoch çš„è¨“ç·´"""
    model.train()
    total_loss = 0
    all_preds = []
    all_labels = []
    criterion = nn.CrossEntropyLoss()
    progress_bar = tqdm(dataloader, desc="Training")
    for batch in progress_bar:
        # å°‡è³‡æ–™ç§»åˆ° GPU
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        
        # æ¸…ç©ºæ¢¯åº¦
        optimizer.zero_grad()
        
        # å‰å‘å‚³æ’­
        logits = model(input_ids, attention_mask)
        
        # è¨ˆç®—æå¤±
        loss = criterion(logits, labels)
        
        # åå‘å‚³æ’­
        loss.backward()
        optimizer.step()
        
        # è¨˜éŒ„æå¤±å’Œé æ¸¬
        total_loss += loss.item()
        preds = torch.argmax(logits, dim=1)
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())
        
        # æ›´æ–°é€²åº¦æ¢
        progress_bar.set_postfix({'loss': loss.item()})
    
    avg_loss = total_loss / len(dataloader)
    accuracy = accuracy_score(all_labels, all_preds)
    return avg_loss, accuracy

# ===== è©•ä¼°å‡½æ•¸ =====
def evaluate(model, dataloader, device):
    """è©•ä¼°æ¨¡å‹æ€§èƒ½"""
    model.eval()
    total_loss = 0
    all_preds = []
    all_labels = []
    criterion = nn.CrossEntropyLoss()
    
    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Evaluating"):
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)
            
            # å‰å‘å‚³æ’­
            logits = model(input_ids, attention_mask)
            
            # è¨ˆç®—æå¤±
            loss = criterion(logits, labels)
            
            total_loss += loss.item()
            preds = torch.argmax(logits, dim=1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
    
    avg_loss = total_loss / len(dataloader)
    accuracy = accuracy_score(all_labels, all_preds)
    
    return avg_loss, accuracy, all_preds, all_labels

# ===== ç¹ªè£½è¨“ç·´æ›²ç·š =====
def plot_training_history(train_losses, train_accs, val_losses, val_accs, save_dir):
    """ç¹ªè£½è¨“ç·´æ­·å²æ›²ç·š"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    
    # æå¤±æ›²ç·š
    epochs = range(1, len(train_losses) + 1)
    ax1.plot(epochs, train_losses, 'b-', label='Training Loss', linewidth=2)
    ax1.plot(epochs, val_losses, 'r-', label='Validation Loss', linewidth=2)
    ax1.set_title('Training and Validation Loss', fontsize=14, fontweight='bold')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # æº–ç¢ºç‡æ›²ç·š
    ax2.plot(epochs, train_accs, 'b-', label='Training Accuracy', linewidth=2)
    ax2.plot(epochs, val_accs, 'r-', label='Validation Accuracy', linewidth=2)
    ax2.set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Accuracy')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    save_path = os.path.join(save_dir, 'training_history.png')
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"\nè¨“ç·´æ­·å²æ›²ç·šå·²å„²å­˜è‡³ {save_path}")
    plt.close()


# ===== ç¹ªè£½æ··æ·†çŸ©é™£ =====
def plot_confusion_matrix(y_true, y_pred, save_dir, class_names=['Negative', 'Positive']):
    """ç¹ªè£½æ··æ·†çŸ©é™£"""
    cm = confusion_matrix(y_true, y_pred)
    
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_names, yticklabels=class_names,
                cbar_kws={'label': 'Count'})
    
    plt.title('Confusion Matrix', fontsize=16, fontweight='bold')
    plt.xlabel('Predicted Label', fontsize=12)
    plt.ylabel('True Label', fontsize=12)
    plt.tight_layout()
    
    save_path = os.path.join(save_dir, 'confusion_matrix.png')
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"æ··æ·†çŸ©é™£å·²å„²å­˜è‡³ {save_path}")
    plt.close()

# ===== å–®æ¬¡å¯¦é©—åŸ·è¡Œå‡½æ•¸ =====
def run_single_experiment(config, exp_num=None, total_exps=None):
    """åŸ·è¡Œå–®æ¬¡å¯¦é©—"""
    MODEL_NAME = config['MODEL_NAME']
    HIDDEN_SIZE = config['HIDDEN_SIZE']
    DROPOUT_RATE = config['DROPOUT_RATE']
    SCHEDULER_TYPE = config['SCHEDULER_TYPE']
    MODEL_TYPE = config['MODEL_TYPE']
    USE_SCHEDULER = (SCHEDULER_TYPE != 'none')
    T_MAX = NUM_EPOCHS
    
    print("="*60)
    if exp_num and total_exps:
        print(f"ğŸ”¬ å¯¦é©— {exp_num}/{total_exps}")
    print("æƒ…ç·’åˆ†é¡æ¨¡å‹è¨“ç·´")
    print("="*60)
    print(f"é…ç½®: æ¨¡å‹={MODEL_NAME.split('/')[-1]}, Hidden={HIDDEN_SIZE}, Dropout={DROPOUT_RATE}, Scheduler={SCHEDULER_TYPE}")
    print("="*60)
    
    # 0. å‰µå»ºå¯¦é©—è³‡æ–™å¤¾
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    exp_dir = os.path.join(EXPERIMENTS_DIR, f"exp_{timestamp}_{MODEL_TYPE}_{MODEL_NAME.split('/')[-1]}")
    os.makedirs(exp_dir, exist_ok=True)
    print(f"\nå¯¦é©—è³‡æ–™å¤¾: {exp_dir}")
    
    # 1. è¼‰å…¥è³‡æ–™
    print("\n[1/5] è¼‰å…¥è³‡æ–™...")
    data_loader = GetDataLoader(MODEL_NAME, use_auth_token=USE_AUTH_TOKEN)
    train_dataloader, val_dataloader, test_dataloader = data_loader.get_DataLoader(
        data_sum=-1,
        batch_size=BATCH_SIZE,
        train_path=TRAIN_PATH,
        val_path=VAL_PATH,
        test_path=TEST_PATH
    )
    print(f"è¨“ç·´é›†æ‰¹æ¬¡æ•¸: {len(train_dataloader)}")
    print(f"é©—è­‰é›†æ‰¹æ¬¡æ•¸: {len(val_dataloader)}")
    print(f"æ¸¬è©¦é›†æ‰¹æ¬¡æ•¸: {len(test_dataloader)}")
    
    # 2. åˆå§‹åŒ–æ¨¡å‹
    print("\n[2/5] åˆå§‹åŒ–æ¨¡å‹...")
    print(f"Tokenizer vocab size: {len(data_loader.tokenizer)}")
    
    if MODEL_TYPE == 'gru':
        model = GRUSentimentClassifier(
            model_name=MODEL_NAME,
            hidden_size=HIDDEN_SIZE,
            num_layers=2,
            num_classes=NUM_CLASSES,
            dropout_rate=DROPOUT_RATE,
            use_auth_token=USE_AUTH_TOKEN,
            tokenizer=data_loader.tokenizer
        )
        print(f"ä½¿ç”¨æ¨¡å‹: GRU Sentiment Classifier")
    elif MODEL_TYPE == 'bigru':
        model = BiGRUSentimentClassifier(
            model_name=MODEL_NAME,
            hidden_size=HIDDEN_SIZE,
            num_layers=2,
            num_classes=NUM_CLASSES,
            dropout_rate=DROPOUT_RATE,
            use_auth_token=USE_AUTH_TOKEN,
            tokenizer=data_loader.tokenizer
        )
        print(f"ä½¿ç”¨æ¨¡å‹: Bidirectional GRU Sentiment Classifier")
    elif MODEL_TYPE == 'lstm':
        model = LSTMSentimentClassifier(
            model_name=MODEL_NAME,
            hidden_size=HIDDEN_SIZE,
            num_layers=2,
            num_classes=NUM_CLASSES,
            dropout_rate=DROPOUT_RATE,
            use_auth_token=USE_AUTH_TOKEN,
            tokenizer=data_loader.tokenizer
        )
        print(f"ä½¿ç”¨æ¨¡å‹: LSTM Sentiment Classifier")
    else:
        model = SentimentClassifier(
            model_name=MODEL_NAME,
            hidden_size=HIDDEN_SIZE,
            num_classes=NUM_CLASSES,
            dropout_rate=DROPOUT_RATE,
            use_auth_token=USE_AUTH_TOKEN,
            tokenizer=data_loader.tokenizer
        )
        print(f"ä½¿ç”¨æ¨¡å‹: Simple Sentiment Classifier")
    
    print(f"Model vocab size: {model.feature_extractor.model.config.vocab_size}")
    
    model.to(device)
    print(f"æ¨¡å‹å·²ç§»è‡³ {device}")
    print(f"æ¨¡å‹åƒæ•¸é‡: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")
    
    # 3. è¨­å®šå„ªåŒ–å™¨è·Ÿæå¤±å‡½æ•¸
    print("\n[3/5] è¨­å®šå„ªåŒ–å™¨...")
    optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)
    print(f"å„ªåŒ–å™¨: AdamW, å­¸ç¿’ç‡: {LEARNING_RATE}")
    
    # è¨­å®šå­¸ç¿’ç‡èª¿åº¦å™¨
    scheduler = None
    if USE_SCHEDULER:
        if SCHEDULER_TYPE == 'cosine':
            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_MAX)
            print(f"å­¸ç¿’ç‡èª¿åº¦å™¨: CosineAnnealingLR (T_max={T_MAX})")
        elif SCHEDULER_TYPE == 'step':
            scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)
            print(f"å­¸ç¿’ç‡èª¿åº¦å™¨: StepLR (step_size=10, gamma=0.1)")
        elif SCHEDULER_TYPE == 'plateau':
            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)
            print(f"å­¸ç¿’ç‡èª¿åº¦å™¨: ReduceLROnPlateau (patience=3)")
        elif SCHEDULER_TYPE == 'exponential':
            scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)
            print(f"å­¸ç¿’ç‡èª¿åº¦å™¨: ExponentialLR (gamma=0.95)")
    
    # 4. è¨“ç·´æ¨¡å‹
    print("\n[4/5] é–‹å§‹è¨“ç·´...")
    train_losses = []
    train_accs = []
    val_losses = []
    val_accs = []
    best_val_acc = 0
    
    for epoch in range(NUM_EPOCHS):
        print(f"\n{'='*60}")
        print(f"Epoch {epoch+1}/{NUM_EPOCHS}")
        print(f"{'='*60}")
        
        # è¨“ç·´
        train_loss, train_acc = train_epoch(model, train_dataloader, optimizer, device)
        train_losses.append(train_loss)
        train_accs.append(train_acc)
        
        # é©—è­‰
        val_loss, val_acc, _, _ = evaluate(model, val_dataloader, device)
        val_losses.append(val_loss)
        val_accs.append(val_acc)
        
        print(f"\nEpoch {epoch+1} çµæœ:")
        print(f"  è¨“ç·´æå¤±: {train_loss:.4f}, è¨“ç·´æº–ç¢ºç‡: {train_acc:.4f}")
        print(f"  é©—è­‰æå¤±: {val_loss:.4f}, é©—è­‰æº–ç¢ºç‡: {val_acc:.4f}")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            model_path = os.path.join(exp_dir, 'best_sentiment_model.pth')
            torch.save(model.state_dict(), model_path)
            print(f"  âœ“ æ–°çš„æœ€ä½³æ¨¡å‹ï¼é©—è­‰æº–ç¢ºç‡: {val_acc:.4f}")
        
        # æ›´æ–°å­¸ç¿’ç‡èª¿åº¦å™¨
        if scheduler is not None:
            if SCHEDULER_TYPE == 'plateau':
                scheduler.step(val_acc)  # ReduceLROnPlateau éœ€è¦ metric
            else:
                scheduler.step()
            current_lr = optimizer.param_groups[0]['lr']
            print(f"  ç•¶å‰å­¸ç¿’ç‡: {current_lr:.2e}")
        
        # æ›´æ–°å­¸ç¿’ç‡èª¿åº¦å™¨
        if scheduler is not None:
            if SCHEDULER_TYPE == 'plateau':
                scheduler.step(val_acc)  # ReduceLROnPlateau éœ€è¦ metric
            else:
                scheduler.step()
            current_lr = optimizer.param_groups[0]['lr']
            print(f"  ç•¶å‰å­¸ç¿’ç‡: {current_lr:.2e}")
    
    # 5. æ¸¬è©¦æ¨¡å‹
    print("\n[5/5] æ¸¬è©¦æœ€ä½³æ¨¡å‹...")
    model_path = os.path.join(exp_dir, 'best_sentiment_model.pth')
    model.load_state_dict(torch.load(model_path))
    test_loss, test_acc, test_preds, test_labels = evaluate(model, test_dataloader, device)
    
    print(f"\n{'='*60}")
    print("æœ€çµ‚æ¸¬è©¦çµæœ")
    print(f"{'='*60}")
    print(f"æ¸¬è©¦æå¤±: {test_loss:.4f}")
    print(f"æ¸¬è©¦æº–ç¢ºç‡: {test_acc:.4f}")
    print("\nè©³ç´°åˆ†é¡å ±å‘Š:")
    print(classification_report(test_labels, test_preds, 
                            #    target_names=['Negative', 'Positive'],
                               digits=4))
    
    # 6. ç¹ªè£½çµæœ
    print("\nç¹ªè£½è¨“ç·´çµæœ...")
    plot_training_history(train_losses, train_accs, val_losses, val_accs, exp_dir)
    plot_confusion_matrix(test_labels, test_preds, exp_dir)
    
    # 7. ä¿å­˜çµæœå ±å‘Š
    report_path = os.path.join(exp_dir, 'training_report.txt')
    with open(report_path, 'w', encoding='utf-8',) as f:
        f.write("æƒ…ç·’åˆ†é¡æ¨¡å‹è¨“ç·´å ±å‘Š\n")
        f.write("="*60 + "\n\n")
        f.write(f"æ¨¡å‹é¡å‹: {MODEL_TYPE}\n")
        f.write(f"é è¨“ç·´æ¨¡å‹: {MODEL_NAME}\n")
        f.write(f"æ‰¹æ¬¡å¤§å°: {BATCH_SIZE}\n")
        f.write(f"å­¸ç¿’ç‡: {LEARNING_RATE}\n")
        f.write(f"è¨“ç·´è¼ªæ•¸: {NUM_EPOCHS}\n")
        f.write(f"éš±è—å±¤å¤§å°: {HIDDEN_SIZE}\n\n")
        f.write(f"æœ€ä½³é©—è­‰æº–ç¢ºç‡: {best_val_acc:.4f}\n")
        f.write(f"æ¸¬è©¦æº–ç¢ºç‡: {test_acc:.4f}\n\n")
        f.write("è©³ç´°åˆ†é¡å ±å‘Š:\n")
        f.write(classification_report(test_labels, test_preds, 
                                    # target_names=['Negative', 'Positive'],
                                     digits=4))
    
    print(f"\nè¨“ç·´å ±å‘Šå·²å„²å­˜è‡³ {report_path}")
    
    # 8. ä¿å­˜ CSV è¨˜éŒ„
    # è¨ˆç®—è©•ä¼°æŒ‡æ¨™
    precision = precision_score(test_labels, test_preds, average='weighted')
    recall = recall_score(test_labels, test_preds, average='weighted')
    f1 = f1_score(test_labels, test_preds, average='weighted')
    
    # æº–å‚™è¨˜éŒ„è³‡æ–™
    record = {
        'å¯¦é©—æ™‚é–“': timestamp,
        'å¤§å‹èªè¨€æ¨¡å‹ç·¨ç¢¼å™¨': MODEL_NAME,
        'åˆ†é¡æ¨¡å‹é¡å‹': MODEL_TYPE,
        'æº–ç¢ºåº¦ (Accuracy)': f'{test_acc:.4f}',
        'ç²¾ç¢ºåº¦ (Precision)': f'{precision:.4f}',
        'å¬å›ç‡ (Recall)': f'{recall:.4f}',
        'F1åˆ†æ•¸ (F1-Score)': f'{f1:.4f}',
        'è¨“ç·´è¼ªæ•¸': NUM_EPOCHS,
        'æ‰¹æ¬¡å¤§å°': BATCH_SIZE,
        'å­¸ç¿’ç‡': LEARNING_RATE,
        'éš±è—å±¤å¤§å°': HIDDEN_SIZE,
        'Dropoutç‡': DROPOUT_RATE,
        'å­¸ç¿’ç‡èª¿åº¦å™¨': SCHEDULER_TYPE if USE_SCHEDULER else 'None'
    }
    
    # å„²å­˜åˆ° experiments è³‡æ–™å¤¾çš„ CSV
    csv_path = os.path.join(EXPERIMENTS_DIR, 'training_records.csv')
    df_record = pd.DataFrame([record])
    
    # å¦‚æœæª”æ¡ˆå·²å­˜åœ¨ï¼Œå‰‡é™„åŠ ï¼ˆappendï¼‰ï¼›å¦å‰‡å‰µå»ºæ–°æª”æ¡ˆ
    if os.path.exists(csv_path):
        # ä½¿ç”¨ mode='a' ç›´æ¥é™„åŠ åˆ°æª”æ¡ˆå°¾ç«¯ï¼Œä¸æœƒè¦†è“‹åŸæœ‰è³‡æ–™
        df_record.to_csv(csv_path, mode='a', header=False, index=False, encoding='utf-8-sig')
    else:
        # æª”æ¡ˆä¸å­˜åœ¨ï¼Œå‰µå»ºæ–°æª”æ¡ˆä¸¦å¯«å…¥æ¨™é¡Œ
        df_record.to_csv(csv_path, mode='w', header=True, index=False, encoding='utf-8-sig')
    
    print(f"\nå¯¦é©—è¨˜éŒ„å·²å„²å­˜è‡³ {csv_path}")
    print(f"\næ‰€æœ‰å¯¦é©—çµæœå·²å„²å­˜è‡³: {exp_dir}")
    print("\nè¨“ç·´å®Œæˆï¼")
    print("="*60)
    
    return {
        'exp_dir': exp_dir,
        'test_acc': test_acc,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'config': config
    }

# ===== è‡ªå‹•çµ„åˆå¯¦é©—ä¸»å‡½æ•¸ =====
def run_all_experiments():
    """è‡ªå‹•åŸ·è¡Œæ‰€æœ‰åƒæ•¸çµ„åˆçš„å¯¦é©—"""
    import itertools
    import time
    
    print("\n" + "ğŸš€"*40)
    print("ğŸš€ è‡ªå‹•çµ„åˆå¯¦é©—ç³»çµ±å•Ÿå‹•")
    print("ğŸš€"*40)
    print(f"é–‹å§‹æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    # ç”Ÿæˆæ‰€æœ‰åƒæ•¸çµ„åˆ
    combinations = list(itertools.product(
        EXPERIMENT_CONFIGS['MODEL_NAMES'],
        EXPERIMENT_CONFIGS['HIDDEN_SIZES'],
        EXPERIMENT_CONFIGS['DROPOUT_RATES'],
        EXPERIMENT_CONFIGS['SCHEDULERS'],
        EXPERIMENT_CONFIGS['MODEL_TYPES']
    ))
    
    total_experiments = len(combinations)
    print(f"ğŸ“Š ç¸½å…±å°‡åŸ·è¡Œ {total_experiments} å€‹å¯¦é©—çµ„åˆ\n")
    print("å¯¦é©—çµ„åˆ:")
    print(f"  - æ¨¡å‹: {len(EXPERIMENT_CONFIGS['MODEL_NAMES'])} ç¨®")
    print(f"  - Hidden Size: {len(EXPERIMENT_CONFIGS['HIDDEN_SIZES'])} ç¨®")
    print(f"  - Dropout Rate: {len(EXPERIMENT_CONFIGS['DROPOUT_RATES'])} ç¨®")
    print(f"  - Scheduler: {len(EXPERIMENT_CONFIGS['SCHEDULERS'])} ç¨®")
    print(f"  - Model Type: {len(EXPERIMENT_CONFIGS['MODEL_TYPES'])} ç¨®")
    print("\n" + "="*80 + "\n")
    
    # åŸ·è¡Œæ‰€æœ‰å¯¦é©—
    results = []
    successful = 0
    failed = 0
    start_time = time.time()
    
    for idx, (model_name, hidden_size, dropout_rate, scheduler, model_type) in enumerate(combinations, 1):
        config = {
            'MODEL_NAME': model_name,
            'HIDDEN_SIZE': hidden_size,
            'DROPOUT_RATE': dropout_rate,
            'SCHEDULER_TYPE': scheduler,
            'MODEL_TYPE': model_type
        }
        
        print(f"\n{'='*80}")
        print(f"é–‹å§‹å¯¦é©— {idx}/{total_experiments}")
        print(f"{'='*80}")
        
        try:
            result = run_single_experiment(config, exp_num=idx, total_exps=total_experiments)
            results.append(result)
            successful += 1
            print(f"\nâœ… å¯¦é©— {idx}/{total_experiments} å®Œæˆ")
        except Exception as e:
            failed += 1
            print(f"\nâŒ å¯¦é©— {idx}/{total_experiments} å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
        
        # é¡¯ç¤ºé€²åº¦
        elapsed = time.time() - start_time
        avg_time = elapsed / idx
        remaining = avg_time * (total_experiments - idx)
        print(f"\nğŸ“Š é€²åº¦: {idx}/{total_experiments} ({idx/total_experiments*100:.1f}%)")
        print(f"â±ï¸  å·²ç”¨æ™‚: {elapsed/60:.1f} åˆ†é˜")
        print(f"â±ï¸  é ä¼°å‰©é¤˜: {remaining/60:.1f} åˆ†é˜")
        print(f"âœ… æˆåŠŸ: {successful} | âŒ å¤±æ•—: {failed}")
    
    # ç¸½çµ
    total_time = time.time() - start_time
    print("\n" + "ğŸ‰"*40)
    print("ğŸ‰ æ‰€æœ‰å¯¦é©—å®Œæˆï¼")
    print("ğŸ‰"*40)
    print(f"\nç¸½çµ:")
    print(f"  ğŸ“Š ç¸½å¯¦é©—æ•¸: {total_experiments}")
    print(f"  âœ… æˆåŠŸ: {successful}")
    print(f"  âŒ å¤±æ•—: {failed}")
    print(f"  â±ï¸  ç¸½è€—æ™‚: {total_time/3600:.2f} å°æ™‚ ({total_time/60:.1f} åˆ†é˜)")
    print(f"  ğŸ“… å®Œæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"\nğŸ“Š æŸ¥çœ‹æ‰€æœ‰å¯¦é©—çµæœ: {EXPERIMENTS_DIR}/training_records.csv")
    print("="*80)
    
    return results


# ===== ä¸»å‡½æ•¸ï¼ˆåŸå§‹ main å‡½æ•¸æ”¹ç‚ºå–®æ¬¡å¯¦é©—ï¼Œæ–°å¢è‡ªå‹•æ¨¡å¼ï¼‰ =====
# def main():  # åŸå§‹å–®æ¬¡å¯¦é©—å‡½æ•¸å·²é‡æ§‹ç‚º run_single_experiment
#     pass


if __name__ == "__main__":
    # è¨­å®šè£ç½®
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")
    
    if AUTO_EXPERIMENT:
        # åŸ·è¡Œæ‰€æœ‰çµ„åˆå¯¦é©—
        run_all_experiments()
    else:
        # åŸ·è¡Œå–®ä¸€å¯¦é©—ï¼ˆéœ€è¦æ‰‹å‹•è¨­å®šåƒæ•¸ï¼‰
        single_config = {
            'MODEL_NAME': 'intfloat/multilingual-e5-large',
            'HIDDEN_SIZE': 256,
            'DROPOUT_RATE': 0.3,
            'SCHEDULER_TYPE': 'cosine',
            'MODEL_TYPE': 'simple',
        }
        run_single_experiment(single_config)